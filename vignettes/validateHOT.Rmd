---
title: "validateHOT - An R Package to Validate Holdout Tasks &#127919;"
author: "Joshua Schramm and Marcel Lichters"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{validateHOT - An R Package to Validate Holdout Tasks &#127919;}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\\VignetteDepends{dplyr}
  %\\VignetteDepends{magrittr}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The functions of <code>validateHOT</code> are twofold: First, <code>validateHOT</code> provides functions to validate a validation/holdout task and ensure whether the model is valid in terms of predicting outside choice sets (i.e., choices that were not included in the model's estimation); second, <code>validateHOT</code> provides functions to run market simulations. Both components are key functions for preference measurement techniques such as CBC, ACBC, or MaxDiff.

We created <code>validateHOT</code> to support students and practitioners who are less familiar with *R*. Moreover, we would also like to provide an easy and convenient way to validate a validation/holdout task for all the [Sawtooth Software](https://sawtoothsoftware.com/) users, who would like to validate their validation/holdout task in *R* for open-science purposes. Finally, the package has expanded in the past years, so `validateHOT` also offers some convenient functions to do some other fun stuff, e.g., running some simulations (e.g., TURF analysis or market simulations).

In this vignette we would like to present to you ...

-   ... how to create utility scores for a validation/holdout task of a *CBC*, *ACBC*, or *MaxDiff* based on the **raw logit utilities** of a *Hierarchical Bayes* estimation which was estimated in *Sawtooth Software*
-   ... how to measure validation metrics which are often reported for a validation/holdout task in research papers
    -   Hit rate (<code>hitrate()</code>)
    -   Kullback-Leibler-Divergence (<code>kl()</code>)
    -   Mean absolute error (<code>mae()</code>)
    -   Mean hit probability (<code>mhp()</code>)
    -   Median absolute error (<code>medae()</code>)
    -   Root-mean-square error (<code>rmse()</code>)
-   ... how to measure metrics of the confusion matrix
    -   <code>accuracy()</code>
    -   F1-score (<code>f1()</code>)
    -   <code>precision()</code>
    -   <code>recall()</code>
    -   <code>specificity()</code>
-   ... how to use <code>validateHOT</code> for simulation purposes
    -   Determine the perfect product assortment with highest reach and frequency; <code>turf()</code>)
    -   Frequency of how many products are bought on average of a specified assortment (<code>freqassort()</code>)
    -   How many participants are reached with a specified assortment (buying at least one alternative of the assortment; <code>reach()</code>)
    -   running market simulations with specified set (<code>marksim()</code>). <code>validateHOT</code> currently provides market simulations based on share of preference as well as first choice rule.
-   ... and finally, how to use <code>validateHOT</code> to convert raw utilities into other scores that easier to interpret
    -   <code>att_imp()</code>
    -   <code>prob_scores()</code>

## Installation

You can install `validateHOT` by using the `devtools` package (Wickham et al., 2022).

```{r}
# install.packages("devtools")
# devtools::install_github("JoshSchramm94/validateHOT")
```

Afterwards, load the package.

```{r setup}
library("validateHOT")
```

Moreover, we also load two packages for later purposes. We also explain some functions using the `tidyverse` logic. To do so, we load the `magrittr` (Bache & Wickham, 2022) and `dplyr` (Wickham et al., 2023) package.

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(magrittr)
```


## `createHOT`: creating validation/holdout task in *R*

At first, we have to create the validation/holdout task, which means that we need to create the utilities for each alternative presented in the validation/holdout task. This is quite easy for a *MaxDiff*, however, for a *CBC* or *ACBC*, we need to add the utilities of each attribute level and might even have to interpolate some values, if they are *linear* or *piecewise* coded.

### MaxDiff

However, let us start with the `MaxDiff`. We use the data set `MaxDiff` that comes with the package and store the utilities in the data set `HOT`. In this example, we assume that we have a validation task with 7 alternatives (`prod = 7`) plus a no-buy alternative (we define the argument by specifying the column index; `none = 19`), so a total of 8 alternatives a participant can choose from. As already mentioned, it is a *MaxDiff* study (`method = "MaxDiff"`). Furthermore, we specify the column index of both the `id` (unique identifier) and `choice` (the actual choice in the validation/holdout task). To specify the 7 alternatives in the validation/holdout task, we use `prod.levels` and specify their column indexes in a `list`. In case we wanted to keep further variables from our original data set, we could use the argument `varskeep` and specify their column index.

**Please be aware that you need to specify the column index and not the column names for the `createHOT()` function!**

```{r, eval = F}
HOT <- createHOT(
  data = MaxDiff, # data frame
  id = 1, # column index of unique identifier
  none = 19, # column index of none alternative
  prod = 7, # no of alternatives in HOT excluding none
  prod.levels = list(3, 10, 11, 15, 16, 17, 18), # column index of alternatives
  method = "MaxDiff", # method applied
  choice = 20 # column index of actual choice
)
```

> In case you have a forced-choice validation/holdout task, do not specify the `none` argument.

### Choice-Based Conjoint

#### Part-Worth utilities only

In case, you conduct a *CBC* (`method = "CBC"`) and all attributes are coded as part-worth, the following example will help you to create the total utilities for your alternatives. We use the `CBC` data set, which comes with `validateHOT`. This example shows a *CBC* with 3 alternatives (`prod = 3`) plus the no-buy alternative, whose utility is stored in column index 21 (`none = 21`). We again specify the column index of `id` and the actual choice, `choice`, in the validation/holdout task.

When using *CBC* or *ACBC*, we need to specify the coding, where `0` stands for part-worth coding, `1` for linear coding, and `2` for piecewise coding. Since we only have part-worth coding we set `coding = c(0, 0, 0)`.

Finally, we specify the attribute levels for each alternative. For example, the first alternative is composed of the following column indexes `c(4, 9, 19)`, namely, `r colnames(CBC)[4]`, `r colnames(CBC)[9]`, and `r colnames(CBC)[19]`. The second is composed of the column indexes `c(8, 12, 17)`, namely, `r colnames(CBC)[8]`, `r colnames(CBC)[12]`, and `r colnames(CBC)[17]`; etc.

```{r, eval = F}
createHOT(
  data = CBC, # data frame
  id = 1, # column index of unique identifier
  none = 21, # column index of none alternative
  prod = 3, # no of alternatives in HOT excluding none
  prod.levels = list(c(4, 9, 19), c(8, 12, 17), c(5, 10, 17)), # column index of the attribute levels for each alternative
  coding = c(0, 0, 0), # coding of the 3 attributes; 0 = part-worth, 1 = linear, 2 = piecewise
  method = "CBC", # method
  choice = 22 # column index of choice
)
```

#### Linear-coded attribute

Now, let us imagine that instead of having all variables coded as part-worth, you also include 1 (or more) variables that are linear-coded. So, let us run again a *CBC* (`method = "CBC"`). All settings are the same as shown in the example above, however, this time we change the coding to `coding = c(0, 0, 1)`, which tells `createHOT()` that the first two attributes are part-worth coded and the last variable is linear coded. How will this impact the way we define our products? We can see that when we specify the third attribute for our three alternatives, we insert a value that this alternative should have for the linear coded variable. In this example, let us assume that the third attribute is weight. The first alternative in our validation/ holdout task is assumed to have a weight of 60 (`c(4, 9, 60)`), the second a weight of `40`, and the last alternative a weight of `45`.

In order to interpolate these values from our attribute levels, we next have to define the values we used for the levels in the Hierarchical Bayes settings. Please be aware that in the case of Sawtooth Software they recommend to recode the values of linear attributes for converging purposes (see, e.g., Orme & Chrzan, 2017, p. 108).

In order to let `createHOT()` interpolate the values for your validation/holdout task, please make sure to insert the exact values you also specify for your *hierarchical Bayes* estimation in Sawtooth. You specify these values in `interpolate.levels` in form of a list. In the example of `CBC_lin`, there are 7 levels ranging from 10 to 70. Please make sure to include **all** levels of the linear-coded attribute. Next, we have to specify the column index of the linear-coded attribute by specifying `lin.p`.

Finally, in our example, we would also like to keep some variables that should be attached to the data frame we are creating. We can specify the column index(es) of the variables we would like to keep in `varskeep`.

> [**Important**]{.underline}: The value you would like to interpolate (in the example below 60, 40, and 45) need to be within the range you specify in `ìnterpolate.levels`. For example, instead of using `c(10, 20, 30, 40, 50, 60, 70)`, we could also use `c(1, 2, 3, 4, 5, 6, 7)` or even better if we zero-center it to `c(-3, -2, -1, 0, 1, 2, 3)`. In this case we would need to adapt the values to be interpolate as well, so in our case 60 becomes 2, 40 becomes 0, and 45 becomes 0.5.

```{r}
HOT <- createHOT(
  data = CBC_lin, # data frame
  id = 1, # column index of unique identifier
  none = 15, # column index of none alternative
  prod = 3, # no of alternatives in HOT excluding none
  prod.levels = list(c(4, 9, 60), c(8, 12, 40), c(5, 10, 45)), # column index of the attribute levels for each alternative (for linear coded we specify the value to be interpolated)
  interpolate.levels = list(c(10, 20, 30, 40, 50, 60, 70)), # actual values for the levels that should be interpolated
  lin.p = 14, # column index of the linear coded variable
  coding = c(0, 0, 1), # coding of the 3 attributes; 0 = part-worth, 1 = linear, 2 = piecewise
  method = "CBC", # method
  varskeep = 17, # column index of variables that should be kept in the data frame
  choice = 16 # column index of choice
)
```

### Adaptive Choice-Based Conjoint (ACBC)

Finally, let us introduce you how to use `validateHOT` for an adaptive choice-based conjoint (ACBC). We also provide two examples, which are typical issues you might face.

#### Linear-coded ACBC price

In the first example, we would like to introduce you the example if you are using a linear-coded price for your ACBC. This price is not coded with 1 in the `coding` argument for the `createHOT()` function. Since it is a little bit different than normal linear-coded variables (i.e., you get 2 coefficients instead of just one), we approach this a bit different.

For our example, we will use the `ACBC` data set, which is also provided by `validateHOT`. If you take a look at the data frame, you see that there are a total of 8 attributes, plus 2 price coefficients (`Price_2.093` as well as `Price_27.287`), and the `none` coefficient. Since all 8 attributes are part-worth coded, the setup is the same as for the CBC.

For our example, we use a validation/holdout task with 6 alternatives plus a no-buy alternative. First, we define the 6 alternatives. We can see that for `prod1`, we again indicate the column indexes for the eight different attributes. Finally, the price (last element of the vector, e.g., `prod1` has a price of `15.99`) is linear-coded.

After defining each alternative in the validation/holdout task, let us look at the `createHOT()` function. We specify our `data`, the column index of `id`, the column index of the no-buy alternative (`none`), the number of alternatives in the validation/holdout task (`prod = 6`), the products, which we have defined before, the method (`ACBC`), and the column index of the actual choice (`choice`). We specify the coding (`c(0, 0, 0, 0, 0, 0, 0, 0, 2)`). Remember that in `createHOT()` we specify a linear-coded price in an ACBC as piecewise, which is why we set the last attribute to `2`. For `interpolate.levels`, we specify the lower bound of our price (`2.093`) and the upper bound of price (`27.287`). Finally, we specify `piece.p`, which is equivalent to `lin.p`, however, we specify the position of the lower and the upper bound of the value we would like to interpolate. Since we only have two values if we have a linear-coded price, i.e., the lower and the upper bound, we specify the position of them. Please be aware that you have to specify the position for each alternative in the validation/holdout task, which is why you have to specify the position `c(35, 36)` for each of the 6 alternatives.

```{r, eval = F}
# define alternatives, for each attribute we specify the column index except for the last one we specify the price to be interpolated.
prod1 <- c(5, 11, 15, 17, 21, 25, 32, 34, 15.99)
prod2 <- c(6, 9, 15, 17, 23, 27, 31, 34, 12.99)
prod3 <- c(8, 12, 16, 19, 23, 24, 28, 34, 12.99)
prod4 <- c(7, 12, 14, 18, 22, 24, 28, 33, 9.99)
prod5 <- c(4, 10, 13, 17, 23, 27, 28, 34, 7.99)
prod6 <- c(5, 9, 14, 17, 23, 27, 29, 33, 9.99)

# calculate total utilities for validation/ holdout task
HOT <- createHOT(
  data = ACBC, # data frame
  id = 1, # column index of the id
  none = 37, # column index of none alternative
  prod = 6, # number of alternatives in validation task (excluding none)
  prod.levels = list(prod1, prod2, prod3, prod4, prod5, prod6), # products specified above
  interpolate.levels = list(c(2.093, 27.287)), # actual values for the levels that should be interpolated, for linear coded price in ACBC this is just the lower bound and the upper bound
  piece.p = list(c(35, 36), c(35, 36), c(35, 36), c(35, 36), c(35, 36), c(35, 36)), # position of the piecewise coded variable
  coding = c(0, 0, 0, 0, 0, 0, 0, 0, 2), # coding of the 9 attributes; 0 = part-worth, 1 = linear, 2 = piecewise
  method = "ACBC", # method
  choice = 38 # column index of choice
)
```

#### Piecewise-coded ACBC

So far, we have only looked at examples where at maximum one attribute was not part-worth coded. In the final example, we will have all three types of coding included. Since piece-wise coding is only available for ACBC in Sawtooth Software, we will show another example with an ACBC. The data set is similar to the one from the previous example (6 alternatives plus a no-buy alternative). We will use the data frame `ACBC_interpolate`, which is also part of `validateHOT`.

The `coding` specified below (`c(0, 1, 0, 0, 0, 0, 0, 0, 2)`) already tells us that attribute 2 is linear-coded, attribute 9 is piecewise coded, while the rest of the attributes are part-worth coded. For this example, we again specify the six alternatives in the `createHOT` function.

For `interpolate.levels`, we have to specify two vectors. The first vector contains the values for the linear-coded attribute 2 (`c(3, 5, 8, 10)`), and the second vector contains the break points you have specified for your piecewise coded price. In `ACBC_interpolate`, we provide an example where we used 7 break points for the price (`c(1.99, 6.99, 9.99, 10.99, 12.99, 17.99, 25.99)`). We specify the column index of the linear-coded attribute in `lin.p`. Next, we specify `piece.p`, the column index of the piecewise-coded attribute. The raw utilities for the 7 break points (`c(1.99, 6.99, 9.99, 10.99, 12.99, 17.99, 25.99)`) are stored in the columns 32 to 38. Again, we need to specify the lower and upper break point of the value we would like to interpolate in `piece.p`, and we need to do this for each of the 6 alternatives. For example, for the first alternative (`15.99`), we see that the lower break point is `12.99` while the upper break point is `17.99`. Therefore, we specify the column index of these two in `piece.p` (`c(36, 37)`). Let us also look at the second product since it represents a scenario you also might face. The alternative should have a price of `12.99`. If we look at the break points we can see that one of the break points is also `12.99`. In this case, we could either use the column index of `12.99` as lower or upper position, the results will be the same.

```{r, eval = F}
HOT <- createHOT(
  data = ACBC_interpolate, # data frame
  id = 1, # column index of the id
  none = 39, # column index of none alternative
  prod = 6, # number of alternatives in validation task (excluding none)
  prod.levels = list(
    c(5, 5, 12, 14, 18, 22, 29, 31, 15.99), # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
    c(6, 4, 12, 14, 20, 24, 28, 31, 12.99), # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
    c(8, 6, 13, 16, 20, 21, 25, 31, 12.99), # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
    c(7, 5, 11, 15, 19, 21, 25, 30, 9.99), # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
    c(4, 9, 10, 14, 20, 24, 25, 31, 7.99), # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
    c(5, 8, 11, 14, 20, 24, 26, 30, 9.99) # column index of the attribute levels for each alternative (for linear coded and piecewise coded we specify value to be interpolated)
  ),
  interpolate.levels = list(c(3, 5, 8, 10), c(1.99, 6.99, 9.99, 10.99, 12.99, 17.99, 25.99)), # actual values for the levels that should be interpolated (first entry refers to the linear coded variable, second entry refers to the piecewise coded variable)
  piece.p = list(c(36, 37), c(35, 36), c(35, 36), c(33, 34), c(33, 34), c(33, 34)), # position of the piecewise coded variable
  lin.p = 9, # position of the linear coded variable
  coding = c(0, 1, 0, 0, 0, 0, 0, 0, 2), # coding of the 9 attributes; 0 = part-worth, 1 = linear, 2 = piecewise
  method = "ACBC", # method
  choice = 40 # column index of choice
)
```

## Validation metrics

First, we focus on metrics that are often reported for validation/holdout tasks in research papers, namely:

-   Hit rate (<code>hitrate()</code>)
-   Kullback-Leibler-Divergence (<code>kl()</code>)
-   Mean absolute error (<code>mae()</code>)
-   Mean hit probability (<code>mhp()</code>)
-   Median absolute error (<code>medae()</code>)
-   Root-mean-square error (<code>rmse()</code>)

### `hitrate`

Once the validation/holdout task is created using `createHOT()`, the setup is similar for all 3 methods. We will use the MaxDiff example from above. Moreover, since we also would like to show some functions exemplary split by groups, we will use the `varskeep` argument.

```{r}
HOT <- createHOT(
  data = MaxDiff, # data frame
  id = 1, # column index of unique identifier
  none = 19, # column index of none alternative
  prod = 7, # no of alternatives in HOT excluding none
  prod.levels = list(3, 10, 11, 15, 16, 17, 18), # column index of alternatives
  method = "MaxDiff", # method applied
  choice = 20, # column index of actual choice
  varskeep = 21
)
```

For `hitrate()`, we specify our data (`HOT` in our case), the column names of alternatives (this includes the no-buy alternative; `opts`), and finally, the actual choice in the holdout task (`choice`).

```{r}
hitrate(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice # column name of choice
)
```

### `kl`

Next, we check the Kullback-Leibler Divergence by running the `kl()` function. Let us first use $log{_2}$ as logarithm base. 

```{r}
kl(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  base = "log2" # logarithm base
)
```

However, we can also use the normal $log$ base. Let us try this in the next step and this time we display the results by using the `tidyverse` logic.

```{r}
HOT %>%
  kl(
    data = ., # data frame
    opts = c(Option_1:None), # column names of alternatives
    choice = choice, # column name of choice
    base = "log" # logarithm base
  )
```

Due to the asymmetry of the Kullback-Leibler divergence, the output provides both `KL_O_P` which is equivalent to (Observed || Predicted) and `KL_P_O` which is equivalent to (Predicted || Observed).

### `mae`

For the mean absolute error, `mae()`, we split the results by the grouping variable `Group`, therefore, we use the `group` argument:

```{r}
mae(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  group = Group # Grouping variable
)
```


### `mhp`

We will display the mean hit probability split by the `Group` variable (`group = Group`):

```{r}
mhp(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  group = Group # Grouping variable
)
```

### `medae`

Next, we look at the median absolute error:

```{r}
medae(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice # column name of choice
)
```


### `rmse`

And finally, to end this block, we look at the root-mean-squared error.

```{r}
rmse(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice # column name of choice
)
```


## Confusion matrix

Next, we will take a look at the 5 metrics of the confusion matrix. The current logic for the confusion matrix is that `validateHOT` calculates, e.g., whether your model overestimates or underestimates purchase behavior. Therefore, you need to specify a `none` alternative for the 5 metrics of confusion matrix, namely ...

-   `accuracy()`
-   `f1()`
-   `precision()`
-   `recall()`
-   `specificity()`

> To translate this to the `validateHOT` logic, imagine you have a validation/holdout task with 5 alternatives plus the alternative not to buy any of those chosen. `validateHOT` now measures whether or not a buy (participant opts for one of the 5 alternatives) or a no-buy (participant opts for the no-buy alternative), respectively, is correctly predicted. 


The setup is similar to the ones of the validation metrics reported above, the only difference is that you have to specify the column index of the no-buy alternative (`none`).

### `accuracy`

We begin with the `accuracy()` and we still work with the `HOT` data frame we created above. We specify the 8 alternatives (7 alternatives + no-buy alternative) as well as the `none` argument, the column name of the no-buy alternative. 

```{r}
accuracy(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  none = None # column name of none alternative
)
```

### `f1`

The code we need to provide to calculate the *F1*-score is exactly the same, however, we use the `f1` function.

```{r}
f1(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  none = None # column name of none alternative
)
```

### `precision`

To display the precision, we use the `precision` function. This time, we want to display the results split by the `Group` variable in `HOT`, therefore, we specify the `group` argument.

```{r}
precision(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  none = None, # column name of none alternative
  group = Group # Grouping variable
)
```

### `recall`

Similar to the validation metrics shown above, we can also implement these functions in `tidyverse` logic. In the following code chunk, we first adjust the `Group` variable to a `factor`. In the last step, we round the results to 2 decimals.

```{r}
HOT %>%
  dplyr::mutate(
    Group = factor(Group,
      levels = c(1:3),
      labels = paste0("Group ", c(1:3))
    )
  ) %>% # change Group to factor
  recall(
    data = ., # data frame
    opts = c(Option_1:None), # column names of alternatives
    choice = choice, # column name of choice
    none = None, # column name of none alternative
    group = Group
  ) %>% # Grouping variable
  mutate_if(
    is.numeric, # only for numeric
    round, # round
    2
  ) # round results to 2 decimals
```



### `specificity`

Finally, the following code runs the `specificity()` function.

```{r}
specificity(
  data = HOT, # data frame
  opts = c(Option_1:None), # column names of alternatives
  choice = choice, # column name of choice
  none = None # column name of none alternative
)
```


## Simulation metrics

Next, let us talk about the simulation metrics. `validateHOT` currently provides the 4 following functions:

-   Reach of the assortment (`reach()`)
-   Frequency of the assortment (`freqAssort()`)
-   **T**(otal) **U**(nduplicated) **R**(each) and **F**(requency) (`turf()`)
-   Market simulations of the assortment (`marksim()`)

### `reach`

Let us imagine you have a specific assortment, and you want to check how many participants consider purchasing at least one of the products or alternatives of this assortment. 

In our case, let us assume we want to test three alternatives - `Option_1`, `Option_4`, and `Option_6` - and see how many participants would consider choosing at least one of these alternatives. 

> **NOTE**: Both `reach()` and `freqassort()` apply the so-called threshold approach. In this case, each alternative which utility exceeds the one of the threshold is considered as, for example, purchase option. In our case, we use the utility of the outside good (i.e., no-buy), however, it could also be the utility of a status quo alternative. A participant is considered as reached, if at least one alternative exceeds this threshold.

```{r}
reach(
  data = HOT, # data frame
  opts = c(Option_1, Option_4, Option_6), # alternatives considered in the assortment
  none = None # threshold that has to be exceeded
)
```


### `freqAssort`

Next, let us check the `freqAssort()` function, which tells you how many products / alternatives on average are preferred over the no-buy alternative. We will use the same example as we did when introducing the `reach()` function.


```{r}
freqassort(
  data = HOT, # data frame
  opts = c(Option_1, Option_4, Option_6), # alternatives considered in the assortment
  none = None # threshold that has to be exceeded
)
```

Again, we could use the `tidyverse` logic and get the results split by a grouping variable (`Group`), if we specify the `group` argument. In the following code chunk, we first adjust the `Group` variable to a `factor`. In the last step, we round the results to 2 decimals.


```{r}
HOT %>%
  dplyr::mutate(
    Group = factor(Group,
      levels = c(1:3),
      labels = paste0("Group ", c(1:3))
    )
  ) %>% # change Group to factor
  freqassort(
    data = ., # data frame
    opts = c(Option_1, Option_4, Option_6), # alternatives considered in the assortment
    none = None, # threshold that has to be exceeded
    group = Group
  ) %>% # Grouping variable
  mutate_if(
    is.numeric, # only for numeric
    round, # round
    2
  ) # round results to 2 decimals
```

### `turf`

Now let us imagine that you are unsure about what the *right* bundle is. `turf()` helps you to determine the perfect bundle based on the its reach and frequency (for explanations, please see above). When applying `turf()`, you can decide between applying the *threshold* (`approach = 'thres'`) or *first choice* (approach = 'fc'`) approach. While former considers each alternative as, for example, purchase option if it exceeds a threshold (Chrzan & Orme, 2019, p. 112), the latter only considers the product alternative with the highest utility (Chrzan & Orme, 2019, p. 112).

This function is extremely helpful when running a `MaxDiff` (Chrzan & Orme, 2019), however, we also show a way to use `turf` with other methods. Let us first assume we ran a MaxDiff study with 16 alternatives and we now want to find out which combination of 3 alternatives can reach most of the participants, put differently, the combination of 3 alternatives for which most of the participants buy at least one alternative. We use the `MaxDiff` data set for this example.

In this example, we have 16 different alternatives included as well as outside option (`none`). To use the `turf()` function, we first have to specify the data frame `data = MaxDiff`. Afterwards, we specify the alternatives (`opts`) that should be considered when creating the different assortments as well as the threshold (`none`) that needs to be exceeded. As described above, the final product assortment should include a total of 3 items (`size = 3`). Finally, we apply the threshold approach (`thres`). We display the first 5 results using the `head()` function. 

```{r}
turf(
  data = MaxDiff,
  opts = c(Option_01:Option_16),
  none = none,
  size = 3,
  approach = "thres"
) %>% 
  head(., n = 5)
```

By default, the results are sorted in descending order by `reach`. We see that `Combo 1` has a `reach` of `r round(turf(data = MaxDiff, opts = c(Option_01:Option_16), none = none, size = 3, approach = "thres") %>% select(reach) %>% .[1,1], digits = 2)`%. This assortment includes `Option_01`, `Option_04`, and `Option_13`. This means that `r round(turf(data = MaxDiff, opts = c(Option_01:Option_16), none = none, size = 3, approach = "thres") %>% select(reach) %>% .[1,1], digits = 2)`% have at least one these 3 alternative exceeding the threshold. Finally, the frequency `freq` of this assortment is `r round(turf(data = MaxDiff, opts = c(Option_01:Option_16), none = none, size = 3, approach = "thres") %>% select(freq) %>% .[1,1], digits = 2)`.

If we decide to rather use the first choice approach, we simply change `approach` to `approach = 'fc'`.

```{r}
turf(
  data = MaxDiff,
  opts = c(Option_01:Option_16),
  none = none,
  size = 3,
  approach = "fc"
) %>% 
  head(., n = 5)
```

We see that the combination with the highest reach has changed. The combination with the highest reach (`reach` equal to `r round(turf(data = MaxDiff, opts = c(Option_01:Option_16), none = none, size = 3, approach = "fc") %>% select(reach) %>% .[1,1], digits = 2)`%) includes `Option_01`, `Option_04`, and `Option_06`. Please be aware that, if `approach = 'fc'`, `reach` and `freq` will be equal since the volume is limited to 1 per participant.

Let us know imagine the case that we already have 2 fixed alternatives, meaning that they have to be included in the assortment, and we want to find 2 further items that maximize `reach`. In `turf()`, we only have to use the `fixed` argument. So let us assume that `Option_02` as well as `Option_12` are fixed.

```{r}
turf(
  data = MaxDiff,
  opts = c(Option_01:Option_16),
  none = none,
  size = 4,
  fixed = c("Option_02", "Option_12"),
  approach = "thres"
) %>% 
  head(., n = 5)
```

We see that adding `Option_01` and `Option_4` yields the highest reach by just changing `approach` to `fc` instead of `thres`.

Finally, you could also specify if there are one or more alternatives or combinations should not be included in any of the solutions. For example, let us take the example from above. Both `Option_02` and `Option_12` should be included. However, neither the combination of `Option_02` and `Option_04` nor the combination of `Option_12` and `Option_09` should be included. 

```{r}
turf(
  data = MaxDiff,
  opts = c(Option_01:Option_16),
  none = none,
  size = 4,
  fixed = c("Option_02", "Option_12"),
  prohib = list(c("Option_02", "Option_04"), c("Option_12", "Option_09")), 
  approach = "thres"
) %>% 
  head(., n = 5)
```

Argument `prohib` has to be list. Moreover, it could also include single alternatives instead of combinations.

If you would like to use `turf()` with data surveyed using, for example, a Likert Scale, you can also do this, however, you need some more data wrangling. Let's say you have 10 items and for each of the items you asked for the purchase likelihood on a 5-point Likert scale (*1 = not very likely to purchase* to *5 = very likely to purchase*). And you want to say that each item is considered as purchase option if participants choose a **4** or **5** on the scale. 

Let us create hypothetical data for this example: 

```{r}
Likert <- base::data.frame(
  alt_01 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_02 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_03 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_04 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_05 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_06 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_07 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_08 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_09 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0),
  alt_10 = base::round(stats::runif(1000, min = 1, max = 5), digits = 0)
)
```

In order to use `turf()`, we need to provide a threshold to the data frame, a value that needs to be exceeded. In our case, we only want to consider option **4** and **5**  on the scale, therefore, the threshold needs to be lower than 4 accordingly (please be aware that setting the threshold to 4 is not working in this case, the threshold **has** to be lower, for example, 3.9999). In our case, since we only have whole numbers we could also set the threshold to **3**. And afterwards, we run the `turf()` function again.

```{r}
Likert %>% 
  mutate(thres = 3) %>% # adds the threshold variable
  turf(data = .,
       opts = c(alt_01:alt_10),
  none = thres,
  size = 3,
  approach = "thres"
) %>% 
  head(., n = 5)
```


### `marksim`

Finally, `validateHOT` also provides a function, `marksim` to calculate the assumed market share of a specified assortment. <code>validateHOT</code> currently provides market simulations based on *share of preference* or *first choice rule*. To specify which market simulation method to run, you can easily decide by specifying the <code>method</code> argument.

#### Share of Preference

```{r}
HOT %>%
  marksim(
    data = ., # data frame
    opts = c(Option_1:None), # column names of alternatives
    method = "shareofpref" # market simulation method
  )
```

#### First Choice rule

```{r}
HOT %>%
  marksim(
    data = ., # data frame
    opts = c(Option_1:None), # column names of alternatives
    method = "firstchoice" # market simulation method
  )
```

## Converting utilities

Finally, we will show how to convert the raw utilities into scores that are easier for interpretation, namely:

-   `att_imp()` to convert raw utilities of (A)CBC into attribute importance scores
-   `prob_scores()` to convert raw utilities of a MaxDiff into choice probabilities

### `att_imp`

Let us again use the examples from above, namely, `CBC`, `CBC_lin`, `ACBC`, and `ACBC_interpolate`.

#### `CBC`

To use `att_imp()`, we first need to specify the `data`. Next, we need to define the attribute levels for each attribute (`attrib`), again, all attribute levels need to be provided. Finally, you specify `coding`, which tells `att_imp` how the attributes were coded (either as part-worth, `0`, or linear, `1`).

```{r}
att_imp(
  data = CBC,
  attrib = list(
    c("Att1_Lev1", "Att1_Lev2", "Att1_Lev3", "Att1_Lev4", "Att1_Lev5"),
    c("Att2_Lev1", "Att2_Lev2", "Att2_Lev3", "Att2_Lev4", "Att2_Lev5"),
    c("Att3_Lev1", "Att3_Lev2", "Att3_Lev3", "Att3_Lev4", "Att3_Lev5", "Att3_Lev6", "Att3_Lev7")
  ),
  coding = c(0, 0, 0)
)
```

#### `CBC_lin`

Next, we assume that one of the variables was linear coded (`Att3_Lin`), which we specify in `coding`. Again, as we had to do for `createHOT()` as well, we need to provide the values that were given to Sawtooth Software for each level (please see explanation above). We specify those in `interpolate.levels` again.

```{r}
att_imp(
  data = CBC_lin,
  attrib = list(
    c("Att1_Lev1", "Att1_Lev2", "Att1_Lev3", "Att1_Lev4", "Att1_Lev5"),
    c("Att2_Lev1", "Att2_Lev2", "Att2_Lev3", "Att2_Lev4", "Att2_Lev5"),
    c("Att3_Lin")
  ),
  coding = c(0, 0, 1),
  interpolate.levels = list(c(10, 20, 30, 40, 50, 60, 70))
)
```

#### `ACBC`

Above, we explained how to address a piecewise coded ACBC in `createHOT()`. As you probably realized there is no `2` in coding. If a variable is piecewise coded, you treat it as it would be part-worth coded. 

```{r}
att_imp(
  data = ACBC,
  attrib = list(
    c("Att1_Lev1", "Att1_Lev2", "Att1_Lev3", "Att1_Lev4", "Att1_Lev5"),
    c("Att2_Lev1", "Att2_Lev2", "Att2_Lev3", "Att2_Lev4"),
    c("Att3_Lev1", "Att3_Lev2", "Att3_Lev3", "Att3_Lev4"),
    c("Att4_Lev1", "Att4_Lev2", "Att4_Lev3"),
    c("Att5_Lev1", "Att5_Lev2", "Att5_Lev3", "Att5_Lev4"),
    c("Att6_Lev1", "Att6_Lev2", "Att6_Lev3", "Att6_Lev4"),
    c("Att7_Lev1", "Att7_Lev2", "Att7_Lev3", "Att7_Lev4", "Att7_Lev5"),
    c("Att8_Lev1", "Att8_Lev2"),
    c("Price_2.093", "Price_27.287")
  ),
  coding = c(rep(0, 9))
)
```


#### `ACBC_interpolate`

Finally, in `ACBC_interpolate` we also had one linear-coded atribute, which we specify in coding again. 

```{r}
att_imp(
  data = ACBC_interpolate,
  attrib = list(
    c("Att1_Lev1", "Att1_Lev2", "Att1_Lev3", "Att1_Lev4", "Att1_Lev5"),
    c("Att2_Lin"),
    c("Att3_Lev1", "Att3_Lev2", "Att3_Lev3", "Att3_Lev4"),
    c("Att4_Lev1", "Att4_Lev2", "Att4_Lev3"),
    c("Att5_Lev1", "Att5_Lev2", "Att5_Lev3", "Att5_Lev4"),
    c("Att6_Lev1", "Att6_Lev2", "Att6_Lev3", "Att6_Lev4"),
    c("Att7_Lev1", "Att7_Lev2", "Att7_Lev3", "Att7_Lev4", "Att7_Lev5"),
    c("Att8_Lev1", "Att8_Lev2"),
    c("Price_1.99", "Price_6.99", "Price_9.99", "Price_9.99", "Price_12.99",
      "Price_17.99", "Price_25.99")
  ),
  coding = c(0, 1, rep(0, 7)),
  interpolate.levels = list(c(3, 5, 8, 10))
)
```



### `prob_scores`

Finally, we will introduce `prob_scores()` which calculates the choice probability scores of an (anchored) MaxDiff. Let us first imagine we ran an unanchored MaxDiff. After specifying the data frame (`data`) as well as the `items`, we have to specify `set.size` which is the number of items that were shown per MaxDiff task. In this example, a participant saw `4` items per task from which s/he had to choose the best and worst item.

```{r}
prob_scores(
  data = MaxDiff,
  items = c(Option_01:Option_16),
  set.size = 4
)
```

The code for the anchored MaxDiff is the same, only that we also have to specify the `anchor` argument, which is the the `none` alternative, however, can also be another threshold variable.

```{r}
prob_scores(
  data = MaxDiff,
  items = c(Option_01:Option_16),
  set.size = 4,
  anchor = "none"
)
```



## References

Bache, S., & Wickham, H. (2022). *magrittr: A Forward-Pipe Operator for R*. R package version 2.0.3, <https://CRAN.R-project.org/package=magrittr>.

Chrzan, K., & Orme, B. K. (2019). <em>Applied MaxDiff: A Practitioner’s Guide to Best-Worst Scaling</em> Provo, UT: Sawtooth Software.

Orme, B. K., & Chrzan, K. (2017). *Becoming an Expert in Conjoint Analysis. Choice Modelling for Pros*. Orem: Sawtooth Software.

Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.2, <https://CRAN.R-project.org/package=dplyr>

Wickham, H., Hester, J., Chang, W., & Bryan, J. (2022). *devtools: Tools to Make Developing R Packages Easier*. R package version 2.4.5, <https://CRAN.R-project.org/package=devtools>.
